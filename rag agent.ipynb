{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5647075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-nomic in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (0.1.4)\n",
      "Requirement already satisfied: langchain_community in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (0.3.27)\n",
      "Requirement already satisfied: tiktoken in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: langchainhub in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (0.1.21)\n",
      "Requirement already satisfied: chromadb in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (1.0.20)\n",
      "Requirement already satisfied: langchain in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (0.3.27)\n",
      "Requirement already satisfied: langgraph in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (0.6.6)\n",
      "Requirement already satisfied: tavily-python in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (0.7.11)\n",
      "Requirement already satisfied: gpt4all in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (2.8.2)\n",
      "Requirement already satisfied: firecrawl-py in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (3.3.2)\n",
      "Requirement already satisfied: langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from langchain-nomic) (0.3.74)\n",
      "Requirement already satisfied: nomic<4.0.0,>=3.1.2 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from langchain-nomic) (3.5.3)\n",
      "Requirement already satisfied: pillow<11.0.0,>=10.3.0 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from langchain-nomic) (10.4.0)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-nomic) (0.4.15)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-nomic) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-nomic) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-nomic) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-nomic) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-nomic) (24.2)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-nomic) (2.11.7)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-nomic) (3.0.0)\n",
      "Requirement already satisfied: click in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from nomic<4.0.0,>=3.1.2->langchain-nomic) (8.2.1)\n",
      "Requirement already satisfied: jsonlines in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from nomic<4.0.0,>=3.1.2->langchain-nomic) (4.0.0)\n",
      "Requirement already satisfied: loguru in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from nomic<4.0.0,>=3.1.2->langchain-nomic) (0.7.3)\n",
      "Requirement already satisfied: rich in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from nomic<4.0.0,>=3.1.2->langchain-nomic) (14.1.0)\n",
      "Requirement already satisfied: requests in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from nomic<4.0.0,>=3.1.2->langchain-nomic) (2.32.5)\n",
      "Requirement already satisfied: numpy in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from nomic<4.0.0,>=3.1.2->langchain-nomic) (2.2.6)\n",
      "Requirement already satisfied: pandas in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from nomic<4.0.0,>=3.1.2->langchain-nomic) (2.3.2)\n",
      "Requirement already satisfied: tqdm in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from nomic<4.0.0,>=3.1.2->langchain-nomic) (4.67.1)\n",
      "Requirement already satisfied: pyarrow in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from nomic<4.0.0,>=3.1.2->langchain-nomic) (21.0.0)\n",
      "Requirement already satisfied: pyjwt in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from nomic<4.0.0,>=3.1.2->langchain-nomic) (2.10.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from langchain_community) (2.0.43)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from langchain_community) (3.12.15)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from langchain_community) (2.10.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from langchain_community) (0.4.1)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from langchain) (0.3.9)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from pydantic>=2.7.4->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-nomic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from pydantic>=2.7.4->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-nomic) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from pydantic>=2.7.4->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-nomic) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from requests->nomic<4.0.0,>=3.1.2->langchain-nomic) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from requests->nomic<4.0.0,>=3.1.2->langchain-nomic) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from requests->nomic<4.0.0,>=3.1.2->langchain-nomic) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from requests->nomic<4.0.0,>=3.1.2->langchain-nomic) (2025.8.3)\n",
      "Requirement already satisfied: greenlet>=1 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from tiktoken) (2025.7.34)\n",
      "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from langchainhub) (2.32.4.20250809)\n",
      "Requirement already satisfied: build>=1.0.3 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from chromadb) (1.3.0)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from chromadb) (1.4.2)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.35.0)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from chromadb) (5.4.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from chromadb) (1.22.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from chromadb) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from chromadb) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from chromadb) (1.36.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from chromadb) (0.21.4)\n",
      "Requirement already satisfied: pypika>=0.48.9 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from chromadb) (1.74.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from chromadb) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from chromadb) (0.16.1)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from chromadb) (33.1.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from chromadb) (5.2.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from chromadb) (3.11.2)\n",
      "Requirement already satisfied: httpx>=0.27.0 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from chromadb) (4.25.1)\n",
      "Requirement already satisfied: six>=1.5 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from langgraph) (2.1.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<0.7.0,>=0.6.0 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from langgraph) (0.6.4)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from langgraph) (0.2.3)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from langgraph) (3.5.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph) (1.10.0)\n",
      "Requirement already satisfied: websockets in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from firecrawl-py) (15.0.1)\n",
      "Requirement already satisfied: nest-asyncio in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from firecrawl-py) (1.6.0)\n",
      "Requirement already satisfied: pyproject_hooks in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: colorama in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: tomli>=1.1.0 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from build>=1.0.3->chromadb) (2.2.1)\n",
      "Requirement already satisfied: anyio in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from httpx>=0.27.0->chromadb) (4.10.0)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.27.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.40.3)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\n",
      "Requirement already satisfied: durationpy>=0.7 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-nomic) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-nomic) (0.24.0)\n",
      "Requirement already satisfied: coloredlogs in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: protobuf in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (6.32.0)\n",
      "Requirement already satisfied: sympy in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.36.0 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.36.0 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.57b0 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.57b0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from rich->nomic<4.0.0,>=3.1.2->langchain-nomic) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from rich->nomic<4.0.0,>=3.1.2->langchain-nomic) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->nomic<4.0.0,>=3.1.2->langchain-nomic) (0.1.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from tokenizers>=0.13.2->chromadb) (0.34.4)\n",
      "Requirement already satisfied: filelock in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.7.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: watchfiles>=0.13 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: pyreadline3 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.5.4)\n",
      "Requirement already satisfied: win32-setctime>=1.0.0 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from loguru->nomic<4.0.0,>=3.1.2->langchain-nomic) (1.2.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from pandas->nomic<4.0.0,>=3.1.2->langchain-nomic) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from pandas->nomic<4.0.0,>=3.1.2->langchain-nomic) (2025.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in e:\\gen ai development\\agentic rag\\.venv\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install -U langchain-nomic langchain_community tiktoken langchainhub chromadb langchain langgraph tavily-python gpt4all firecrawl-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b9d3da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# SETUP INSTRUCTIONS:\n",
    "# 1. Create a .env file / or copy the example .env file in the project root directory\n",
    "# 2. Add your API keys to the .env file (see .env.example for format)\n",
    "# 3. Get your API keys from:\n",
    "#    - LangChain: https://smith.langchain.com/\n",
    "#    - FireCrawl: https://firecrawl.dev/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "381e8857",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_llm = 'llama3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46025bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents scraped: 8\n",
      "Number of documents before filtering: 127\n",
      "Number of documents after filtering: 127\n",
      "Number of documents before filtering: 127\n",
      "Number of documents after filtering: 127\n"
     ]
    }
   ],
   "source": [
    "### Index\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "# from langchain_community.document_loaders import FireCrawlLoader\n",
    "from firecrawl import FirecrawlApp\n",
    "from langchain_community.vectorstores.utils import filter_complex_metadata\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "urls = [\n",
    "    \"https://www.drupal.org/blog?page=1\",\n",
    "    \"https://www.drupal.org/blog?page=2\",\n",
    "    \"https://www.drupal.org/blog?page=3\",\n",
    "    \"https://www.drupal.org/blog?page=4\",\n",
    "    \"https://www.drupal.org/blog?page=5\",\n",
    "    \"https://www.drupal.org/blog?page=6\",\n",
    "    \"https://www.drupal.org/blog?page=7\",\n",
    "    \"https://www.drupal.org/blog?page=8\"\n",
    "]\n",
    "\n",
    "\n",
    "app = FirecrawlApp(api_key=os.environ['FIRECRAWL_API_KEY'])\n",
    "\n",
    "docs = []\n",
    "for url in urls:\n",
    "    try:\n",
    "        scraped_data = app.scrape(url=url, formats=[\"markdown\"])\n",
    "        # Check if scraped_data exists and extract content\n",
    "        if scraped_data:\n",
    "            content = None\n",
    "            \n",
    "            # Extract content based on the object type and available attributes\n",
    "            if hasattr(scraped_data, 'page_content'):\n",
    "                content = scraped_data.page_content\n",
    "            elif hasattr(scraped_data, 'content'):\n",
    "                content = scraped_data.content\n",
    "            elif hasattr(scraped_data, 'markdown'):\n",
    "                content = scraped_data.markdown\n",
    "            elif hasattr(scraped_data, 'text'):\n",
    "                content = scraped_data.text\n",
    "            \n",
    "            if content and content.strip():  # Make sure content is not empty\n",
    "                # Store as dictionary first\n",
    "                docs.append({\n",
    "                    'page_content': content,\n",
    "                    'metadata': {'source': url}\n",
    "                })\n",
    "                # print(f\"Successfully added document from {url}, content length: {len(content)}\")\n",
    "            else:\n",
    "                print(f\"No valid content found for {url}\")\n",
    "        else:\n",
    "            print(f\"No data returned for {url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to scrape {url}: {e}\")\n",
    "\n",
    "print(f\"Number of documents scraped: {len(docs)}\")\n",
    "# print(docs[:2])  # Print first two documents for verification\n",
    "# split documents\n",
    "# docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "# Create Document objects from dictionaries and split them\n",
    "doc_objects = [Document(page_content=doc['page_content'], metadata=doc['metadata']) for doc in docs]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=250, chunk_overlap=0)\n",
    "\n",
    "doc_splits = text_splitter.split_documents(doc_objects)\n",
    "\n",
    "print(f\"Number of documents before filtering: {len(doc_splits)}\")\n",
    "\n",
    "# Filter out complex metadata and ensure proper document formatting\n",
    "filtered_docs = []\n",
    "for doc in doc_splits:\n",
    "    # Ensure the document is an instance of Document and has a 'metadata' attribute\n",
    "    if isinstance(doc, Document) and hasattr(doc, 'metadata'):\n",
    "        clean_metadata = {k: v for k, v in doc.metadata.items() if isinstance(v, (str, int, float, bool))}\n",
    "        filtered_docs.append(Document(page_content=doc.page_content, metadata=clean_metadata))\n",
    "\n",
    "print(f\"Number of documents after filtering: {len(filtered_docs)}\")\n",
    "\n",
    "# Add to vectorDB\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=filtered_docs,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=GPT4AllEmbeddings(),\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a69d8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection details:\n",
      "- Name: rag-chroma\n",
      "- Count: 127\n",
      "\n",
      "Peek at stored data:\n",
      "- IDs: ['a629ee59-8c5e-4886-9e52-3a5c8fc44ac1', 'c25d0ace-4d33-4a05-a1d8-35592759a83b']\n",
      "- Documents preview: ['[Skip to main content](https://www.drupal.org/blog?page=1#content) [Skip to search](https://www.drup...', '[Learn how to support DDEV](https://ddev.com/support-ddev/#sponsor-development)\\n\\n# Drupal blog\\n\\n## [...']\n",
      "- Metadatas: [{'source': 'https://www.drupal.org/blog?page=1'}, {'source': 'https://www.drupal.org/blog?page=1'}]\n"
     ]
    }
   ],
   "source": [
    "### Inspect the underlying Chroma collection\n",
    "\n",
    "collection = vectorstore._collection\n",
    "print(f\"Collection details:\")\n",
    "print(f\"- Name: {collection.name}\")\n",
    "print(f\"- Count: {collection.count()}\")\n",
    "\n",
    "# Get a peek at the actual stored data\n",
    "peek_data = collection.peek(limit=2)\n",
    "print(f\"\\nPeek at stored data:\")\n",
    "print(f\"- IDs: {peek_data.get('ids', [])}\")\n",
    "print(f\"- Documents preview: {[doc[:100] + '...' for doc in peek_data.get('documents', [])]}\")\n",
    "print(f\"- Metadatas: {peek_data.get('metadatas', [])}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e889f754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 'yes'}\n"
     ]
    }
   ],
   "source": [
    "### Retrieval Grader with LLM\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "#LLM\n",
    "llm = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "  template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing relevance of a retrieved document to a user question. If the document contains keywords related to the user question, grade it as relevant. It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "  Give a binary score 'yes' or 'no' based on the relevance of the document to the question. \\n\n",
    "  Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\n",
    "   <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "   Here is the retrieved document: \\n\\n {document} \\n\\n\n",
    "   Here is the user question: {question} \\n <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "   input_variables=[\"document\", \"question\"]\n",
    ")\n",
    "\n",
    "retrieval_grader = prompt | llm | JsonOutputParser()\n",
    "question = \"what is going on in Drupal community?\"\n",
    "docs = retriever.invoke(question)\n",
    "docs_txt = docs[1].page_content\n",
    "print(retrieval_grader.invoke({\"question\": question, \"document\": docs_txt}))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
